코르카에서 생각하는 **AI 네이티브 제품 팀**, 좀 더 구체적으로는 **좋은 에이전틱 엔지니어링 프로세스 & 프랙티스가 정착된 제품 팀**의 이상적인 모습을 묘사하면 다음과 같다.

1. 코드리뷰에 쓰는 시간은 줄어들고, 대신 (스펙) 프롬프트 리뷰와 짝 프롬프팅이 늘어난다.
2. 각자가 사용하는 프롬프트가 코드베이스 내에(또는 깃헙 등에) 자산화된다. 새 도구/방법론을 사용해보는 실험 및 공유가 빈번하게 일어나고(예: 매주 슬랙에 이번주 본인이 새로 실험해본 도구, 프로세스, 워크플로우 등이 공유됨) 이러한 경험이 누적되어 다시 팀에 전파되며 자산화된다.
3. 직군별 역할 구분이 모호해진다. 기획자와 디자이너가 코드를 짜서 데모를 working prototype으로 보여주거나 직접 PR을 작성하는 일이 늘고, 개발자도 프론트엔드/백엔드/DB/인프라 등 모든 곳에 개입하며, 나아가 기획/마케팅 등 제품 개발의 전 영역을 다룰 수 있다. 여기에 필요한 지식 학습과 직군간 대화도 빈번하게 일어난다.
4. 사람이 컴퓨터로 직접 하는 모든 일은 어떻게든 코드(결정론적 알고리즘이 담긴 스크립트 등)나 LLM으로 대체할 수 있다고 믿으며, 일부라도 대체하기 위해 적극적으로 노력한다. 권한이나 보안 등의 문제로 처음부터 완전 자동화를 하는 건 대개 어렵지만, 사람이 파일을 올려주거나 내용을 복사해주거나 하는 방식으로 접착제 역할을 해준다면 생각보다 아주 많은 일이 가능해진다.
5. 메인 제품의 코드 품질에 모두가 적극적으로 투자한다. 코드베이스의 코드 품질이 높아질수록 코딩 에이전트가 일을 더 잘 한다는 사실을 모두가 이해한다. 코드 품질 지표가 대시보드 등으로 관리되고, 우상향될 수 있는 프랙티스가 정착된다(매일 tidying 등). 기존 코드베이스의 품질이 높고 E2E 테스트 코드가 잘 갖춰져 있어서 대규모 리팩토링이 두렵지 않은 상태가 된다.
6. 코드 품질을 높이는 도구를 비롯하여, 기존에는 ‘구현하기만 했다면 팀의 효율을 높였겠지만 우선순위가 밀려서 구현하지 않았던’ 많은 papercut work이 실제로 구현된다. 백오피스 어드민, 다양한 린터 룰, 테스트 코드, 정적 분석 스크립트 등.
7. (기존 레거시와의 의존성이 적은) 새로 시작하는 프로젝트는 되도록이면 한 사람이 처음부터 끝까지 다 한다. 자료 조사, 디자인, 마케팅, 법무 검토 등 각 단계에서 타 직군 전문가와의 협업이 필요하면 그 때만 짝 작업을 한다.
8. **자료 조사 → 스펙 티켓 → 스펙 문서 정교화 → 학습 및 스펙 문서 리뷰 → 구현 지시 → 회고 → 코드리뷰** 싸이클이 정착된다.
    1. 첫 스펙을 Jira 티켓/Github 이슈 등에 작성한다. 이 첫 스펙을 만들기 위해 들어갈 정보들이 LLM이 읽기 좋은 형태로 준비되어 있고, 이 정보를 취합하는 도구들(MCP, 스크립트, 커스텀 프롬프트 등. 예: [slack-to-md skill](https://github.com/corca-ai/public-agents-and-skills/tree/main/.claude/skills/slack-to-md))이 준비되어 있다. 필요하다면 스펙 작성 전에도 이러한 도구를 이용해 자료 조사를 한다. ‘LLM이 읽기 좋은 형태의 데이터’를 준비하는 게 대부분의 조직에서는 첫 병목이 된다.
    2. 첫 스펙 프롬프트를 가능하면 짝으로 작성하며 토론한다. 왜 그렇게 작성하는지, 그 생각을 어떻게 했는지, 이대로 요청하면 코딩 에이전트가 어디서 어떤 실수를 할 것 같은지 등등.
    3. 스펙을 정교하게 만드는 도구(예: [Clarify skill](https://github.com/corca-ai/public-agents-and-skills/tree/main/.claude/skills/clarify))가 준비되어 있다. 로컬에서 직접 트리거할 수도 있고 Github Action 등을 통해 자동화될 수도 있다. 이 도구와 대화를 나누며 스펙 문서를 정교하게 만든다.
    4. 정교화된 스펙을 스스로 검토할 수 있는 능력이 부족하다면 적극적으로 (AI와 함께, 다른 사람과 함께) 학습한다. 도메인 지식, 기술적 의사결정, 코드베이스에 대한 지식 등.
    5. 이렇게 정교해진 스펙을 코딩 에이전트에게 던져서 (PLAN 모드를 거친 다음) 첫 턴에 원하는 기능이 나오게 하는 걸 연습한다.
    6. 원하는 기능이 한번에 안 나왔다면 회고한다. 에이전트에게 '이러저러한 이유로 원하는 대로 되지 않았는데, 처음에 어떻게 했으면 원하는대로 나왔을까?' 묻고, 그 응답대로 다시 구현해본다. 이러한 경험을 팀에 공유한다. (이 모든 과정이 깃헙 이슈나 PR description, 커밋 로그 등에 남는다)
    7. 구현 완료 후에는 코드리뷰를 돕는 에이전트(코드래빗 또는 Github Action 등으로 직접 구축)로 리뷰를 미리 받아 인간이 직접 리뷰할 부분이 최대한 적어지게 한다. 잘못 구현한 부분(False positive)과 구현했어야 했는데 빼먹은 부분(False negative) 모두에 대해 회고하고, ‘처음에 어떻게 했어야 이 실수를 하지 않았을까’를 배운다.